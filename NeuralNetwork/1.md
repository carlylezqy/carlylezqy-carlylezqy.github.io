Semantic Segmentationとは、各画素がどの物体に属するのかを推定する技術である。

単一クラス画像認識 (Image Classification)(LeNet etc.)

(多クラス) 物体認識 (Object detection)(R-CNN, Yolo, etc.)

画像分割 (Semantic Segmentation)(FCN, U-Net)



使ったデータセット

Stanford Background Dataset(9 classes)

<img src="/Users/caujoeng/Downloads/iShot2021-06-14 09.22.02.png" alt="iShot2021-06-14 09.22.02" style="zoom:50%;" />

**Ground Truth** (正解ラベル、教師データ)

FCNでは、一般物体認識の畳み込みニューラルネットワーク(e.g.VGG-16)の全結合層を1×1の畳み込み層に置き換えている。

全結合層を無くすことで、従来の畳み込みニューラルネットワークのように入力画像のサイズを固定する制約がなくなった。また、クラス分類の結果が**ヒートマップ**(*Heatmap*)として出力されるようになる。

特徴マップをupsamplingで入力画像と同サイズに拡大するだけなら、物体の境界が模糊になる。

特徴抽出の最終層だけでなく、途中のpooling層で出力される大きいサイズの特徴マップも活用する。特徴マップのサイズは各層で異なるので、最終層の特徴マップから順にアップサンプリングで前の層と同サイズに拡大し、チャンネルごとに足し算する。

<img src="/Users/caujoeng/Downloads/iShot2021-06-14 09.29.07.png" alt="iShot2021-06-14 09.29.07" style="zoom:50%;" />

Fully Convolutional Networks for Semantic Segmentation Jonathan Long et al.

1. Only pooling and prediction layers are shown; intermediate convolution layers (including our converted fully connected layers) are omitted.
2. Solid line (FCN-32s): Our single-stream net, upsamples stride 32 predictions back to pixels in a single step. 
3. Dashed line (FCN-16s): Combining predictions from both the final layer and the pool4 layer, at stride 16, lets our net predict finer details, while retaining high-level semantic information.高レベルのセマンティック情報を持ちながら、より細かい詳細を予測できるようになる。
4. Dotted line (FCN-8s): Additional predictions from pool3, at stride 8, provide further precision.

<img src="/Users/caujoeng/Downloads/iShot2021-06-14 09.58.07.png" alt="iShot2021-06-14 09.58.07" style="zoom:50%;" />



FCN8sを用いたStanford Background Datasetの予測

<img src="/Users/caujoeng/Desktop/1623343388.3085475.jpg" alt="1623343388.3085475" style="zoom: 50%;" />

<img src="/Users/caujoeng/Desktop/1623343401.9827971.jpg" alt="1623343401.9827971" style="zoom:50%;" />

<img src="/Users/caujoeng/Desktop/1623343415.7018304.jpg" alt="1623343415.7018304" style="zoom:50%;" />





**Conv and** Transposed Convolution
$$
\text { input }=\left[\begin{array}{cccc}
x_{1} & x_{2} & x_{3} & x_{4} \\
x_{5} & x_{6} & x_{7} & x_{8} \\
x_{9} & x_{10} & x_{11} & x_{12} \\
x_{13} & x_{14} & x_{15} & x_{16}
\end{array}\right]
$$

$$
\text { Kernel }=\left[\begin{array}{lll}
w_{0,0} & w_{0,1} & w_{0,2} \\
w_{1,0} & w_{1,1} & w_{1,2} \\
w_{2,0} & w_{2,1} & w_{2,2}
\end{array}\right]
$$

When strides=1, padding=0, then output=2x2
$$
\text { input }=\left[\begin{array}{llllllllllllllll}
x_{1} & x_{2} & x_{3} & x_{4} & x_{5} & x_{6} & x_{7} & x_{8} & x_{9} & x_{10} & x_{11} & x_{12} & x_{13} & x_{14} & x_{15} & x_{16}
\end{array}\right]^{\top}
$$

$$
\text { output }=\left[\begin{array}{llll}
y_{1} & y_{2} & y_{3} & y_{4}
\end{array}\right]^{\top}
$$

